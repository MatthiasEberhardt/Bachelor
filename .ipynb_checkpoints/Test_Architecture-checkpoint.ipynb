{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import rasterio\n",
    "import rasterio.features\n",
    "import rasterio.warp\n",
    "from rasterio.plot import show\n",
    "from fastai.data.all import *\n",
    "from fastai.vision.all import *\n",
    "#from fastai.vision.image import *\n",
    "import fastbook\n",
    "import fastai\n",
    "fastbook.setup_book()\n",
    "from fastbook import *\n",
    "from fastai.vision.widgets import *\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "import torch\n",
    "from torch.overrides import *\n",
    "from torch.nn.functional import *\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "from torch.nn import *\n",
    "#from IPython.core.debugg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fastai.device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `accuracy` not found.\n"
     ]
    }
   ],
   "source": [
    "untar_data??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('C:/Users/Almut Eberhardt/.fastai/data/mnist_sample')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.MNIST_SAMPLE)\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('C:/Users/Almut Eberhardt/.fastai/data/mnist_sample/train')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp=(path/'train')\n",
    "tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copied from https://github.com/fastai/fastai/blob/f633356359a29f8d869ce36659f7aa25660e946a/fastai/data/transforms.py#L230\n",
    "class Categorize_OneHot(DisplayedTransform):\n",
    "    \"Reversible transform of category string to `vocab` id\"\n",
    "    loss_func,order=CrossEntropyLossFlat(),1\n",
    "    def __init__(self, vocab=None, sort=True, add_na=False):\n",
    "        if vocab is not None: vocab = CategoryMap(vocab, sort=sort, add_na=add_na)\n",
    "        store_attr()\n",
    "\n",
    "    def setups(self, dsets):\n",
    "        if self.vocab is None and dsets is not None: self.vocab = CategoryMap(dsets, sort=self.sort, add_na=self.add_na)\n",
    "        self.c = len(self.vocab)\n",
    "\n",
    "    def encodes(self, o):\n",
    "        try:\n",
    "            #change to one-hot-encoding\n",
    "            \n",
    "            length=len(self.vocab.o2i)\n",
    "            y_vec=torch.zeros(length)\n",
    "            y_vec[self.vocab.o2i[o]]=1\n",
    "            return TensorCategory(y_vec.type(torch.LongTensor))#TensorCategory(self.vocab.o2i[o])\n",
    "        except KeyError as e:\n",
    "            raise KeyError(f\"Label '{o}' was not included in the training dataset\") from e\n",
    "    #change\n",
    "    def decodes(self, o): \n",
    "        index=torch.argmax(o)\n",
    "        return Category(self.vocab[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "images=DataBlock(\n",
    "    #blocks=(ImageBlock,TransformBlock(type_tfms=Categorize_OneHot(vocab=None, sort=True, add_na=False))),\n",
    "    blocks=(ImageBlock,CategoryBlock),\n",
    "    #TransformBlock(type_tfms=Categorize_OneHot(vocab=None, sort=True, add_na=False))),\n",
    "    #TransformBlock(type_tfms=Categorize32f(vocab=None, sort=True, add_na=False))),\n",
    "    get_items=get_image_files,\n",
    "    splitter=RandomSplitter(valid_pct=0.2,seed=42),\n",
    "    get_y=parent_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls=images.dataloaders(tp,num_workers=0,batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Test_Net,self).__init__()\n",
    "        self.Conv1=nn.Conv2d(3,50,kernel_size=3,padding=1)\n",
    "        self.ReLU1=nn.ReLU()\n",
    "        self.Pool1=nn.MaxPool2d(kernel_size=2)\n",
    "        self.Conv2=nn.Conv2d(50,24,kernel_size=3,padding=1)\n",
    "        self.ReLU2=nn.ReLU()\n",
    "        self.Pool2=nn.MaxPool2d(kernel_size=2)\n",
    "        self.Conv3=nn.Conv2d(24,4,kernel_size=3,padding=1)\n",
    "        self.ReLU3=nn.ReLU()\n",
    "        self.Pool3=nn.MaxPool2d(kernel_size=2)\n",
    "        #print(type(self.Pool3))\n",
    "        self.Flat1=Flatten()\n",
    "        self.Dense1=nn.Linear(36,100)\n",
    "        self.ReLU4=nn.ReLU()\n",
    "        self.Dense2=nn.Linear(100,2)\n",
    "        self.ReLU5=nn.ReLU()\n",
    "        #self.Softmax=nn.Softmax(dim=1)\n",
    "        #self.Flat2=Flatten()\n",
    "    def forward(self,x):\n",
    "        print(\"forward\")\n",
    "        res=self.Conv1(x)\n",
    "        res=self.ReLU1(res)\n",
    "        res=self.Pool1(res)\n",
    "        res=self.Conv2(res)\n",
    "        res=self.ReLU2(res)\n",
    "        res=self.Pool2(res)\n",
    "        res=self.Conv3(res)\n",
    "        res=self.ReLU3(res)\n",
    "        res=self.Pool3(res)\n",
    "        res=self.Flat1(res)\n",
    "        #print(res.shape)\n",
    "        res=self.Dense1(res)\n",
    "        res=self.ReLU4(res)\n",
    "        res=self.Dense2(res)\n",
    "        #res=self.Softmax(res)\n",
    "        #res=self.Flat2(res)\n",
    "        res=self.ReLU5(res)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BCELoss_mod(_WeightedLoss):\n",
    "    r\"\"\"Creates a criterion that measures the Binary Cross Entropy\n",
    "    between the target and the output:\n",
    "\n",
    "    The unreduced (i.e. with :attr:`reduction` set to ``'none'``) loss can be described as:\n",
    "\n",
    "    .. math::\n",
    "        \\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad\n",
    "        l_n = - w_n \\left[ y_n \\cdot \\log x_n + (1 - y_n) \\cdot \\log (1 - x_n) \\right],\n",
    "\n",
    "    where :math:`N` is the batch size. If :attr:`reduction` is not ``'none'``\n",
    "    (default ``'mean'``), then\n",
    "\n",
    "    .. math::\n",
    "        \\ell(x, y) = \\begin{cases}\n",
    "            \\operatorname{mean}(L), & \\text{if reduction} = \\text{'mean';}\\\\\n",
    "            \\operatorname{sum}(L),  & \\text{if reduction} = \\text{'sum'.}\n",
    "        \\end{cases}\n",
    "\n",
    "    This is used for measuring the error of a reconstruction in for example\n",
    "    an auto-encoder. Note that the targets :math:`y` should be numbers\n",
    "    between 0 and 1.\n",
    "\n",
    "    Notice that if :math:`x_n` is either 0 or 1, one of the log terms would be\n",
    "    mathematically undefined in the above loss equation. PyTorch chooses to set\n",
    "    :math:`\\log (0) = -\\infty`, since :math:`\\lim_{x\\to 0} \\log (x) = -\\infty`.\n",
    "    However, an infinite term in the loss equation is not desirable for several reasons.\n",
    "\n",
    "    For one, if either :math:`y_n = 0` or :math:`(1 - y_n) = 0`, then we would be\n",
    "    multiplying 0 with infinity. Secondly, if we have an infinite loss value, then\n",
    "    we would also have an infinite term in our gradient, since\n",
    "    :math:`\\lim_{x\\to 0} \\frac{d}{dx} \\log (x) = \\infty`.\n",
    "    This would make BCELoss's backward method nonlinear with respect to :math:`x_n`,\n",
    "    and using it for things like linear regression would not be straight-forward.\n",
    "\n",
    "    Our solution is that BCELoss clamps its log function outputs to be greater than\n",
    "    or equal to -100. This way, we can always have a finite loss value and a linear\n",
    "    backward method.\n",
    "\n",
    "\n",
    "    Args:\n",
    "        weight (Tensor, optional): a manual rescaling weight given to the loss\n",
    "            of each batch element. If given, has to be a Tensor of size `nbatch`.\n",
    "        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
    "            the losses are averaged over each loss element in the batch. Note that for\n",
    "            some losses, there are multiple elements per sample. If the field :attr:`size_average`\n",
    "            is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
    "            when reduce is ``False``. Default: ``True``\n",
    "        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
    "            losses are averaged or summed over observations for each minibatch depending\n",
    "            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
    "            batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
    "        reduction (string, optional): Specifies the reduction to apply to the output:\n",
    "            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n",
    "            ``'mean'``: the sum of the output will be divided by the number of\n",
    "            elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n",
    "            and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n",
    "            specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n",
    "\n",
    "    Shape:\n",
    "        - Input: :math:`(N, *)` where :math:`*` means, any number of additional\n",
    "          dimensions\n",
    "        - Target: :math:`(N, *)`, same shape as the input\n",
    "        - Output: scalar. If :attr:`reduction` is ``'none'``, then :math:`(N, *)`, same\n",
    "          shape as input.\n",
    "\n",
    "    Examples::\n",
    "\n",
    "        >>> m = nn.Sigmoid()\n",
    "        >>> loss = nn.BCELoss()\n",
    "        >>> input = torch.randn(3, requires_grad=True)\n",
    "        >>> target = torch.empty(3).random_(2)\n",
    "        >>> output = loss(m(input), target)\n",
    "        >>> output.backward()\n",
    "    \"\"\"\n",
    "    __constants__ = ['reduction']\n",
    "\n",
    "    def __init__(self, weight: Optional[Tensor] = None, size_average=None, reduce=None, reduction: str = 'mean') -> None:\n",
    "        super(BCELoss_mod, self).__init__(weight, size_average, reduce, reduction)\n",
    "\n",
    "    def forward(self, input: Tensor, target: Tensor) -> Tensor:\n",
    "        #print(input.shape)\n",
    "        #target=target[:,None]\n",
    "        target=target.type(torch.float)\n",
    "        #print(target.shape)\n",
    "        return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn=Test_Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_mod(inp, targ, axis=-1):\n",
    "    \"Compute accuracy with `targ` when `pred` is bs * n_classes\"\n",
    "    #print(inp)\n",
    "    #print(targ.shape)\n",
    "    #pred,targ = flatten_check(inp.argmax(dim=axis), targ)\n",
    "    pred=inp.argmax(dim=axis)\n",
    "    targ=targ.argmax(dim=axis)\n",
    "    #print(pred)\n",
    "    return (pred == targ).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, resnet34(), loss_func=CrossEntropyLoss_mod(), metrics=accuracy)\n",
    "#learn.model=learn.model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.310656</td>\n",
       "      <td>0.161453</td>\n",
       "      <td>0.973376</td>\n",
       "      <td>02:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.186612</td>\n",
       "      <td>0.092458</td>\n",
       "      <td>0.979427</td>\n",
       "      <td>02:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.087225</td>\n",
       "      <td>0.043477</td>\n",
       "      <td>0.989109</td>\n",
       "      <td>02:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.026793</td>\n",
       "      <td>0.012940</td>\n",
       "      <td>0.997580</td>\n",
       "      <td>02:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.023015</td>\n",
       "      <td>0.042484</td>\n",
       "      <td>0.987495</td>\n",
       "      <td>02:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.012192</td>\n",
       "      <td>0.997176</td>\n",
       "      <td>02:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.002590</td>\n",
       "      <td>0.009417</td>\n",
       "      <td>0.996773</td>\n",
       "      <td>02:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.027038</td>\n",
       "      <td>0.005460</td>\n",
       "      <td>0.998386</td>\n",
       "      <td>02:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.002140</td>\n",
       "      <td>0.005747</td>\n",
       "      <td>0.998790</td>\n",
       "      <td>02:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.001369</td>\n",
       "      <td>0.005383</td>\n",
       "      <td>0.998790</td>\n",
       "      <td>02:54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(10, 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "CrossEntropyLoss??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropyLoss_mod(_WeightedLoss):\n",
    "    r\"\"\"This criterion combines :func:`nn.LogSoftmax` and :func:`nn.NLLLoss` in one single class.\n",
    "\n",
    "    It is useful when training a classification problem with `C` classes.\n",
    "    If provided, the optional argument :attr:`weight` should be a 1D `Tensor`\n",
    "    assigning weight to each of the classes.\n",
    "    This is particularly useful when you have an unbalanced training set.\n",
    "\n",
    "    The `input` is expected to contain raw, unnormalized scores for each class.\n",
    "\n",
    "    `input` has to be a Tensor of size either :math:`(minibatch, C)` or\n",
    "    :math:`(minibatch, C, d_1, d_2, ..., d_K)`\n",
    "    with :math:`K \\geq 1` for the `K`-dimensional case (described later).\n",
    "\n",
    "    This criterion expects a class index in the range :math:`[0, C-1]` as the\n",
    "    `target` for each value of a 1D tensor of size `minibatch`; if `ignore_index`\n",
    "    is specified, this criterion also accepts this class index (this index may not\n",
    "    necessarily be in the class range).\n",
    "\n",
    "    The loss can be described as:\n",
    "\n",
    "    .. math::\n",
    "        \\text{loss}(x, class) = -\\log\\left(\\frac{\\exp(x[class])}{\\sum_j \\exp(x[j])}\\right)\n",
    "                       = -x[class] + \\log\\left(\\sum_j \\exp(x[j])\\right)\n",
    "\n",
    "    or in the case of the :attr:`weight` argument being specified:\n",
    "\n",
    "    .. math::\n",
    "        \\text{loss}(x, class) = weight[class] \\left(-x[class] + \\log\\left(\\sum_j \\exp(x[j])\\right)\\right)\n",
    "\n",
    "    The losses are averaged across observations for each minibatch. If the\n",
    "    :attr:`weight` argument is specified then this is a weighted average:\n",
    "\n",
    "    .. math::\n",
    "        \\text{loss} = \\frac{\\sum^{N}_{i=1} loss(i, class[i])}{\\sum^{N}_{i=1} weight[class[i]]}\n",
    "\n",
    "    Can also be used for higher dimension inputs, such as 2D images, by providing\n",
    "    an input of size :math:`(minibatch, C, d_1, d_2, ..., d_K)` with :math:`K \\geq 1`,\n",
    "    where :math:`K` is the number of dimensions, and a target of appropriate shape\n",
    "    (see below).\n",
    "\n",
    "\n",
    "    Args:\n",
    "        weight (Tensor, optional): a manual rescaling weight given to each class.\n",
    "            If given, has to be a Tensor of size `C`\n",
    "        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
    "            the losses are averaged over each loss element in the batch. Note that for\n",
    "            some losses, there are multiple elements per sample. If the field :attr:`size_average`\n",
    "            is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
    "            when reduce is ``False``. Default: ``True``\n",
    "        ignore_index (int, optional): Specifies a target value that is ignored\n",
    "            and does not contribute to the input gradient. When :attr:`size_average` is\n",
    "            ``True``, the loss is averaged over non-ignored targets.\n",
    "        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
    "            losses are averaged or summed over observations for each minibatch depending\n",
    "            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
    "            batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
    "        reduction (string, optional): Specifies the reduction to apply to the output:\n",
    "            ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will\n",
    "            be applied, ``'mean'``: the weighted mean of the output is taken,\n",
    "            ``'sum'``: the output will be summed. Note: :attr:`size_average`\n",
    "            and :attr:`reduce` are in the process of being deprecated, and in\n",
    "            the meantime, specifying either of those two args will override\n",
    "            :attr:`reduction`. Default: ``'mean'``\n",
    "\n",
    "    Shape:\n",
    "        - Input: :math:`(N, C)` where `C = number of classes`, or\n",
    "          :math:`(N, C, d_1, d_2, ..., d_K)` with :math:`K \\geq 1`\n",
    "          in the case of `K`-dimensional loss.\n",
    "        - Target: :math:`(N)` where each value is :math:`0 \\leq \\text{targets}[i] \\leq C-1`, or\n",
    "          :math:`(N, d_1, d_2, ..., d_K)` with :math:`K \\geq 1` in the case of\n",
    "          K-dimensional loss.\n",
    "        - Output: scalar.\n",
    "          If :attr:`reduction` is ``'none'``, then the same size as the target:\n",
    "          :math:`(N)`, or\n",
    "          :math:`(N, d_1, d_2, ..., d_K)` with :math:`K \\geq 1` in the case\n",
    "          of K-dimensional loss.\n",
    "\n",
    "    Examples::\n",
    "\n",
    "        >>> loss = nn.CrossEntropyLoss()\n",
    "        >>> input = torch.randn(3, 5, requires_grad=True)\n",
    "        >>> target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "        >>> output = loss(input, target)\n",
    "        >>> output.backward()\n",
    "    \"\"\"\n",
    "    __constants__ = ['ignore_index', 'reduction']\n",
    "    ignore_index: int\n",
    "\n",
    "    def __init__(self, weight: Optional[Tensor] = None, size_average=None, ignore_index: int = -100,\n",
    "                 reduce=None, reduction: str = 'mean') -> None:\n",
    "        super(CrossEntropyLoss_mod, self).__init__(weight, size_average, reduce, reduction)\n",
    "        self.ignore_index = ignore_index\n",
    "\n",
    "    def forward(self, input: Tensor, target: Tensor) -> Tensor:\n",
    "        target=target.type(torch.int64)\n",
    "        return F.cross_entropy(input, target, weight=self.weight,\n",
    "                               ignore_index=self.ignore_index, reduction=self.reduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
